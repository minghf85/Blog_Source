+++
author = "Ming"
title = "cuda quick start"
date = "2025-04-23"
description = "Cuda C++的快速入门"
tags = [
    "Cuda",
    "C++"
]
series = ["cuda"]
series_order = 1
+++

## Cuda环境的配置
条件：
- 支持cuda的显卡，目前即老黄的N卡，不必多说。
- 有C/C++基础
目前我使用的平台是Windows+Vscode，配上C++的插件，命令行**nvcc**编译运行**cuda**程序。
如果你还没有配置好任何环境，请自行搜索，过程对新手会比较麻烦，不过还请坚持下去。
## 检查运行
1. 新建文件main.cu，粘贴以下内容
   ```cpp
   #include <stdio.h>

   __global__ void helloFromGPU()
   {
      printf("Hello World from GPU!\n");
   }

   int main()
   {
      printf("Hello World from CPU!\n");
      helloFromGPU<<<1, 1>>>();
      cudaDeviceSynchronize();
      return 0;
   }
      ```
2. 终端编译运行，注意程序路径
   ```bash
   nvcc main.cu -o main
   ./main
   ```
3. 结果比对
   程序运行后应该输出：
   ```
   Hello World from CPU!
   Hello World from GPU!
   ```
   如果看到这两行输出，说明CUDA环境配置成功。

## CUDA程序结构详解

### 1. 程序基本结构

典型的单文件CUDA程序包含以下组成部分：

```cpp
// 头文件包含
#include <cuda_runtime.h>
#include <stdio.h>

// 设备函数声明
__global__ void kernel_function(params);  // GPU内核函数

// 主机函数声明
void host_function(params);              // CPU主机函数

int main() {
    // 主机代码 (CPU执行)
    // 1. 数据准备和内存分配
    // 2. 设备内存分配
    // 3. 数据传输(主机->设备)
    
    // 内核调用 (GPU执行)
    kernel_function<<<grid, block>>>(args);
    
    // 同步等待
    cudaDeviceSynchronize();
    
    // 结果处理
    // 1. 数据传输(设备->主机)
    // 2. 内存释放
    // 3. 结果验证
    
    return 0;
}

// 设备函数定义
__global__ void kernel_function(params) {
    // GPU执行的并行代码
}

// 主机函数定义
void host_function(params) {
    // CPU执行的辅助函数
}
```

### 2. 关键元素说明

#### 函数类型限定符
| 限定符      | 执行位置 | 调用位置 | 说明 |
|------------|---------|---------|------|
| `__global__` | GPU     | CPU/GPU | 内核函数，异步执行 |
| `__device__` | GPU     | GPU     | 设备函数，只能被其他设备函数或内核调用 |
| `__host__`   | CPU     | CPU     | 主机函数(可省略) |

#### 内核调用语法
```cpp
kernel_name<<<grid_dim, block_dim, shared_mem_size, stream>>>(args);
```

参数说明：
- `grid_dim`: dim3类型，指定网格维度(线程块数量)
- `block_dim`: dim3类型，指定线程块维度(每块线程数)
- `shared_mem_size`: 可选，动态共享内存大小(字节)
- `stream`: 可选，执行流指针

#### 同步函数
```cpp
cudaError_t cudaDeviceSynchronize();
```
- 阻塞主机线程，直到所有GPU操作完成
- 返回错误码(cudaSuccess表示成功)

### 3. 编译命令详解

#### 基本编译命令
```bash
nvcc [options] input_file.cu -o output_file
```

#### 常用编译选项

| 选项 | 说明 |
|------|------|
| `-o <file>` | 指定输出文件名 |
| `-arch=<arch>` | 指定目标GPU架构(如sm_61) |
| `-G` | 生成调试信息(影响性能) |
| `-O0/-O1/-O2/-O3` | 优化级别(0-3) |
| `-std=c++11` | 使用C++11标准 |
| `-lineinfo` | 生成行号信息(不影响优化) |
| `-Xcompiler "<options>"` | 传递选项给主机编译器 |
| `-I<path>` | 添加包含目录 |
| `-L<path>` | 添加库目录 |
| `-l<library>` | 链接指定库 |

#### 架构指定示例
```bash
# 为Pascal架构(GTX 10系列)编译
nvcc -arch=sm_61 program.cu -o program

# 为多代架构生成代码
nvcc -arch=compute_61 -code=sm_61,sm_70 program.cu -o program
```

#### 调试与优化
```bash
# 调试版本
nvcc -G -g -O0 program.cu -o program_debug

# 发布版本
nvcc -O3 -arch=sm_75 program.cu -o program_release
```

### 4. 典型执行流程

1. **初始化阶段**:
   - 设备内存分配(`cudaMalloc`)
   - 主机到设备数据传输(`cudaMemcpy`)

2. **执行阶段**:
   - 启动内核(`<<<>>>`语法)
   - 可选: 流管理、事件记录

3. **收尾阶段**:
   - 设备到主机数据传输(`cudaMemcpy`)
   - 内存释放(`cudaFree`)
   - 错误检查(`cudaGetLastError`)

## 简单的尝试

### 1. 矩阵加法